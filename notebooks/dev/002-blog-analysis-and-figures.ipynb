{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import altair as alt\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from altair_saver import save\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from ci_mapping.data.mag_orm import (Paper, \n",
    "                                     Author,\n",
    "                                     AuthorAffiliation,\n",
    "                                     Affiliation,\n",
    "                                     AffiliationLocation,\n",
    "                                     PaperAuthor,\n",
    "                                     FieldOfStudy,\n",
    "                                     PaperFieldsOfStudy,\n",
    "                                     Conference,\n",
    "                                     Journal, \n",
    "                                     PaperFlag,\n",
    "                                     AffiliationType, \n",
    "                                     AuthorAffiliation, \n",
    "                                     AffiliationLocation, \n",
    "                                     OpenAccess, \n",
    "                                     FosMetadata, \n",
    "                                     Conference)\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the configuration file and create a session.\n",
    "db_config = 'postgres+psycopg2://postgres@localhost/ci_deployment'\n",
    "engine = create_engine(db_config)\n",
    "Session = sessionmaker(engine)\n",
    "s = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tables\n",
    "mag = pd.read_sql(s.query(Paper).statement, s.bind)\n",
    "flag = pd.read_sql(s.query(PaperFlag).statement, s.bind)\n",
    "aff_type = pd.read_sql(s.query(AffiliationType).statement, s.bind)\n",
    "paper_author_aff = pd.read_sql(s.query(AuthorAffiliation).statement, s.bind)\n",
    "\n",
    "# Join papers with flag\n",
    "mag = mag.merge(flag, left_on='id', right_on='id')\n",
    "paper_author_aff = paper_author_aff.drop(['id'], axis=1).merge(aff_type, left_on='affiliation_id', right_on='id')\n",
    "paper_author_aff = paper_author_aff.rename(index=str, columns={'type':'non_company'})\n",
    "paper_author_aff = paper_author_aff.merge(mag[['type', 'year', 'id']], left_on='paper_id', right_on='id')\n",
    "aff_papers = paper_author_aff.drop_duplicates(['affiliation_id', 'paper_id'])\n",
    "aff_location = pd.read_sql(s.query(AffiliationLocation).statement, s.bind)\n",
    "open_access = pd.read_sql(s.query(OpenAccess).statement, s.bind)\n",
    "journals = pd.read_sql(s.query(Journal).statement, s.bind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences = pd.read_sql(s.query(Conference).statement, s.bind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some columns have null values registered as 'NaN'\n",
    "mag['bibtex_doc_type'] = mag.bibtex_doc_type.replace('NaN', np.nan)\n",
    "mag['publisher'] = mag.publisher.replace('NaN', np.nan)\n",
    "mag['references'] = mag.references.replace('NaN', np.nan)\n",
    "mag['abstract'] = mag.abstract.replace('NaN', np.nan)\n",
    "mag['doi'] = mag.doi.replace('NaN', np.nan)\n",
    "\n",
    "# String to list\n",
    "mag['references'] = mag.references.apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else np.nan)\n",
    "\n",
    "# Change the publication and the bibtex document types\n",
    "publication_type_ = {'0':np.nan, \n",
    "                     '1':'Journal article', \n",
    "                     '2':'Patent', \n",
    "                     '3':'Conference paper',\n",
    "                     '4':'Book chapter',\n",
    "                     '5':'Book',\n",
    "                     '6':'Book reference entry', \n",
    "                     '7':'Dataset', \n",
    "                     '8':'Repository'}\n",
    "\n",
    "bibtext_doc_type_ = {'a':'Journal article', 'b':'Book', 'c':'Book chapter', 'p':'Conference paper'}\n",
    "\n",
    "mag['publication_type'] = mag.publication_type.apply(lambda x: publication_type_[x])\n",
    "mag['bibtex_doc_type'] = mag.bibtex_doc_type.apply(lambda x: bibtext_doc_type_[x] if isinstance(x, str) else np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag['month_year'] = pd.to_datetime(mag['date']).dt.to_period('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mag.isnull().sum() / mag.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of papers in AI, CI, AI+CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Papers per category\n",
    "mag.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual increase of publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for cat in mag.type.unique():\n",
    "    frame = pd.DataFrame(mag[mag.type==cat].groupby('year')['id'].count() / mag[mag.type==cat].groupby('year')['id'].count().iloc[0]).reset_index()\n",
    "    frame = pd.DataFrame(frame).rename(index=str, columns={'id':'value'})\n",
    "    frame['type'] = cat\n",
    "    frames.append(frame)\n",
    "    \n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_line(point=True).encode(\n",
    "    x='year',\n",
    "    y='value',\n",
    "    color='type',\n",
    ").properties(title='Annual publication increase (base year = 2000)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations through time in categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mag.groupby(['year', 'type'])['citations'].mean()).reset_index()\n",
    "\n",
    "alt.Chart(df).mark_circle(\n",
    "    opacity=1,\n",
    "    stroke='black',\n",
    "    strokeWidth=0.5\n",
    ").encode(\n",
    "    alt.X('year', axis=alt.Axis(labelAngle=0)),\n",
    "    alt.Y('type'),\n",
    "    alt.Size('citations',\n",
    "        scale=alt.Scale(range=[0, 1500]),\n",
    "        legend=alt.Legend(title='Citations')\n",
    "    ),\n",
    "    alt.Color('type', legend=None)\n",
    ").properties(\n",
    "    width=780,\n",
    "    height=150, title='Average citations for AI, CI and AI+CI'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Share of publications in AI, CI, AI+CI by firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for (num, comp) in zip([0,1], ['non-Firm', 'Firm']):\n",
    "    for cat in aff_papers.type.unique():\n",
    "        data = aff_papers[aff_papers.non_company==num].drop_duplicates('paper_id')\n",
    "        nominator = data[data.type==cat].groupby('year')['paper_id'].count()\n",
    "        denominator = data[data.type==cat].groupby('year')['paper_id'].count().iloc[0]\n",
    "        frame = pd.DataFrame(nominator / denominator).reset_index()\n",
    "        frame = pd.DataFrame(frame).rename(index=str, columns={'paper_id':'value'})\n",
    "        frame['type'] = cat\n",
    "        frame['category'] = comp\n",
    "        frames.append(frame)\n",
    "    \n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_point(opacity=1).encode(\n",
    "    x=alt.X('category:N', title=None),\n",
    "    y=alt.Y('value:Q'),\n",
    "    color=alt.Color('type:N'),\n",
    "    column='year'\n",
    ").properties(\n",
    "    width=20\n",
    ").configure_facet(\n",
    "    spacing=18\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## International collaborations: % of cross-country teams in AI, CI, AI+CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff_location = aff_location.dropna(subset=['country'])\n",
    "# merge paper_apaper_author_aff with location data\n",
    "df = paper_author_aff.merge(aff_location[['affiliation_id', 'country']], left_on='affiliation_id', right_on='affiliation_id')\n",
    "df = df.drop_duplicates(['paper_id', 'affiliation_id'])\n",
    "# group countries\n",
    "df = df.groupby(['type', 'year', 'paper_id'])['country'].apply(list)\n",
    "df = pd.DataFrame(df)\n",
    "# binary label showing if a paper had affiliations from different countries\n",
    "df['cross_country_collab'] = df.country.apply(lambda x: 1 if len(set(x)) > 1 else 0)\n",
    "# multiply by 100 to get the proportion\n",
    "df = pd.DataFrame(df.reset_index().groupby(['type', 'year'])['cross_country_collab'].mean() * 100).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubbles = alt.Chart(df).mark_point().encode(\n",
    "    alt.X(\n",
    "        'year',\n",
    "        title=\"Year\",\n",
    "#         sort=alt.EncodingSortField(field=\"delta\", order='descending'),\n",
    "        scale=alt.Scale(zero=False),\n",
    "        axis=alt.Axis(grid=False, labelAngle=0),\n",
    "    ),\n",
    "    alt.Y(\n",
    "        'cross_country_collab',\n",
    "        title=\"(%)\",\n",
    "#         sort='-x',\n",
    "        axis=alt.Axis(grid=False)\n",
    "    ),\n",
    "    color=alt.Color('type', legend=alt.Legend(title=\"Category\")),\n",
    "    ).properties(\n",
    "        width=720,\n",
    "        title='Cross-country collaboration in AI, CI, AI+CI'\n",
    "    )\n",
    "\n",
    "line = alt.Chart(df).mark_line(strokeWidth=1,color='darkgrey',strokeDash=[1,1]).encode(alt.X('year'),  alt.Y('cross_country_collab'), detail='year')\n",
    "\n",
    "\n",
    "bubbles + line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industry - academia collaborations: % in AI, CI, AI+CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = paper_author_aff.drop_duplicates(['paper_id', 'affiliation_id'])\n",
    "# group countries\n",
    "df = df.groupby(['type', 'year', 'paper_id'])['non_company'].apply(list)\n",
    "df = pd.DataFrame(df)\n",
    "# binary label showing if a paper had affiliations from industry and academia\n",
    "df['industry_academia_collab'] = df.non_company.apply(lambda x: 1 if len(set(x)) > 1 else 0)\n",
    "# multiply by 100 to get the proportion\n",
    "df = pd.DataFrame(df.reset_index().groupby(['type', 'year'])['industry_academia_collab'].mean() * 100).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubbles = alt.Chart(df).mark_point().encode(\n",
    "    alt.X(\n",
    "        'year',\n",
    "        title=\"Year\",\n",
    "#         sort=alt.EncodingSortField(field=\"delta\", order='descending'),\n",
    "        scale=alt.Scale(zero=False),\n",
    "        axis=alt.Axis(grid=False, labelAngle=0),\n",
    "    ),\n",
    "    alt.Y(\n",
    "        'industry_academia_collab',\n",
    "        title=\"(%)\",\n",
    "#         sort='-x',\n",
    "        axis=alt.Axis(grid=False)\n",
    "    ),\n",
    "    color=alt.Color('type', legend=alt.Legend(title=\"Category\")),\n",
    "    ).properties(\n",
    "        width=720,\n",
    "        title='Industry-academia collaboration in AI, CI, AI+CI'\n",
    "    )\n",
    "\n",
    "line = alt.Chart(df).mark_line(strokeWidth=1,color='darkgrey',strokeDash=[1,1]).encode(alt.X('year'), alt.Y('industry_academia_collab'), detail='year')\n",
    "\n",
    "\n",
    "bubbles + line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adoption of open access by AI, CI, AI+CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_journal = mag[['id', 'year', 'type']].merge(journals, left_on='id', right_on='paper_id').merge(open_access, left_on='id_y', right_on='id')\n",
    "\n",
    "frames = []\n",
    "for (num, comp) in zip([0,1], ['Paywalled', 'Open Access']):\n",
    "    for cat in paper_journal.type.unique():\n",
    "        data = paper_journal[paper_journal.open_access==num].drop_duplicates('paper_id')\n",
    "        nominator = data[data.type==cat].groupby('year')['paper_id'].count()\n",
    "        denominator = data[data.type==cat].groupby('year')['paper_id'].count().iloc[0]\n",
    "        frame = pd.DataFrame(nominator / denominator).reset_index()\n",
    "        frame = pd.DataFrame(frame).rename(index=str, columns={'paper_id':'value'})\n",
    "        frame['type'] = cat\n",
    "        frame['category'] = comp\n",
    "        frames.append(frame)\n",
    "    \n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_point(opacity=1).encode(\n",
    "    x=alt.X('category:N', title=None),\n",
    "    y=alt.Y('value:Q'),\n",
    "    color=alt.Color('type:N'),\n",
    "    column='year'\n",
    ").properties(\n",
    "    width=20\n",
    ").configure_facet(\n",
    "    spacing=18\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field of Study usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfos = pd.read_sql(s.query(PaperFieldsOfStudy).statement, s.bind)\n",
    "fos = pd.read_sql(s.query(FieldOfStudy).statement, s.bind)\n",
    "pfos = pfos.merge(fos, left_on='field_of_study_id', right_on='id')[['paper_id', 'field_of_study_id', 'name']]\n",
    "fos_metadata = pd.read_sql(s.query(FosMetadata).statement, s.bind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (mag\n",
    "      .merge(pfos[pfos.field_of_study_id.isin(fos_metadata[fos_metadata.level==1]['id'].unique())], \n",
    "             left_on='id', \n",
    "             right_on='paper_id'))\n",
    "df = df[['paper_id', 'type', 'year', 'name']]\n",
    "\n",
    "# Combine most used CI and AI+CI FoS\n",
    "ci_top_fos = df[df.type=='ci'].name.value_counts().index[:20]\n",
    "aici_top_fos = df[df.type=='ai_ci'].name.value_counts().index[:20]\n",
    "combined_fos = set(ci_top_fos.append(aici_top_fos))\n",
    "\n",
    "df = pd.DataFrame(df.groupby(['type', 'year', 'name'])['paper_id'].count()).reset_index()\n",
    "df = df[df.type.isin(['ci', 'ai_ci'])]\n",
    "df = df[df.name.isin(combined_fos)]\n",
    "\n",
    "df['year'] = df.year.astype(int)\n",
    "\n",
    "lst = []\n",
    "for year in df.year.unique():\n",
    "    for name in df.name.unique():\n",
    "        if len(df[(df.name==name) & (df.year==year)]['type'].values) == 2:\n",
    "            continue\n",
    "        elif len(df[(df.name==name) & (df.year==year)]['type'].values) == 1:\n",
    "            if df[(df.name==name) & (df.year==year)]['type'].values[0] == 'ci':\n",
    "                lst.append({'type':'ai_ci', 'year':year, 'name':name, 'paper_id':0})\n",
    "            else:\n",
    "                lst.append({'type':'ci', 'year':year, 'name':name, 'paper_id':0})\n",
    "        else:\n",
    "            lst.append({'type':'ai_ci', 'year':year, 'name':name, 'paper_id':0})\n",
    "            lst.append({'type':'ci', 'year':year, 'name':name, 'paper_id':0})\n",
    "            \n",
    "df = pd.concat([df, pd.DataFrame(lst)])\n",
    "\n",
    "fraq = []\n",
    "for _, row in df.iterrows():\n",
    "    fraq.append((row['paper_id'] / df[(df.type==row['type']) & (df.year==row['year'])]['paper_id'].sum()) * 100)\n",
    "    \n",
    "df['fraq'] = fraq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slider = alt.binding_range(min=2000, max=2020, step=2)\n",
    "select_year = alt.selection_single(name='year', fields=['year'],\n",
    "                                   bind=slider, init={'year': 2000})\n",
    "\n",
    "base = alt.Chart(df).add_selection(\n",
    "    select_year\n",
    ").transform_filter(\n",
    "    select_year\n",
    ").transform_calculate(\n",
    "    category=alt.expr.if_(alt.datum.type == 'ci', 'CI', 'AI+CI')\n",
    ").properties(\n",
    "    width=350,\n",
    ")\n",
    "\n",
    "color_scale = alt.Scale(domain=['CI', 'AI+CI'])\n",
    "\n",
    "left = base.transform_filter(\n",
    "    alt.datum.category == 'CI'\n",
    ").encode(\n",
    "    y=alt.Y('name', axis=None),\n",
    "    x=alt.X('fraq',\n",
    "            title='(%)', sort=alt.SortOrder('descending')),\n",
    "    color=alt.Color('category:N', legend=None)\n",
    ").mark_bar().properties(title='CI')\n",
    "\n",
    "middle = base.encode(\n",
    "    y=alt.Y('name', axis=None),\n",
    "    text=alt.Text('name'),\n",
    ").mark_text().properties(width=120)\n",
    "\n",
    "right = base.transform_filter(\n",
    "    alt.datum.category == 'AI+CI'\n",
    ").encode(\n",
    "    y=alt.Y('name', axis=None),\n",
    "    x=alt.X('fraq', title='(%)'),\n",
    "    color=alt.Color('category:N', scale=color_scale, legend=None)\n",
    ").mark_bar().properties(title='AI+CI')\n",
    "\n",
    "f = alt.concat(left, middle, right, spacing=5)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(f, 'chart.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Journals and conferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences = mag[['type', 'id', 'year']].merge(conferences, left_on='id', right_on='paper_id').drop(['id_y', 'id_x'], axis=1)\n",
    "conference_fos = conferences.merge(pfos, left_on='paper_id', right_on='paper_id').merge(fos_metadata, left_on='field_of_study_id', right_on='id')\n",
    "cfos = conference_fos[(conference_fos.type=='ci') & (conference_fos.level==2)]\n",
    "g = pd.DataFrame(cfos.groupby('conference_name')['name'].apply(Counter)).reset_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for _, row in g[g.name>5].iterrows():\n",
    "    G.add_edge(row['conference_name'], row['level_1'], weight=row['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in G.nodes:\n",
    "    if node in g.conference_name.unique():\n",
    "        G.nodes[node]['color'] = '#ff7e0e'\n",
    "    else:\n",
    "        G.nodes[node]['color'] = '#1f76b4'\n",
    "        \n",
    "G.remove_node('Educational technology')\n",
    "G.remove_node('icalt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(G, '../../data/processed/conferences_fos_278_420.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fields of study heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (mag\n",
    "      .merge(pfos[pfos.field_of_study_id.isin(fos_metadata[fos_metadata.level.isin([1,2,3,4])]['id'].unique())], \n",
    "             left_on='id', \n",
    "             right_on='paper_id'))\n",
    "df = df[['paper_id', 'type', 'year', 'name']]\n",
    "\n",
    "df = df[df.type!='ai']\n",
    "df = pd.DataFrame(df.groupby(['type', 'year', 'name'])['paper_id'].count()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    df[(df.type=='ai_ci') & (df.paper_id > 20)],\n",
    "    title=\"AI+CI: Most used Fields of Study\"\n",
    ").mark_rect().encode(\n",
    "    alt.X('year'),\n",
    "    alt.Y('name:O', sort='x'),\n",
    "    alt.Color('paper_id', scale=alt.Scale(scheme=\"viridis\"), title='Count'),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('name', title='Field of Study'),\n",
    "        alt.Tooltip('paper_id', title='Count')\n",
    "    ]\n",
    ").properties(width=700, height=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    df[(df.type=='ci') & (df.paper_id > 80)],\n",
    "    title=\"CI: Most used Fields of Study\"\n",
    ").mark_rect().encode(\n",
    "    alt.X('year'),\n",
    "    alt.Y('name:O', sort='x'),\n",
    "    alt.Color('paper_id', scale=alt.Scale(scheme=\"viridis\"), title='Count'),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('name', title='Field of Study'),\n",
    "        alt.Tooltip('paper_id', title='Count')\n",
    "    ]\n",
    ").properties(width=700, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic distribution of AI, CI, AI+CI research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff_location = aff_location.dropna(subset=['country'])\n",
    "# merge paper_apaper_author_aff with location data\n",
    "df = paper_author_aff.merge(aff_location[['affiliation_id', 'country']], left_on='affiliation_id', right_on='affiliation_id')\n",
    "df = df.drop_duplicates(['paper_id', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_ci = pd.DataFrame(df.groupby(['type', 'year', 'country'])['paper_id'].count().loc['ai_ci'].sort_values(ascending=False)).reset_index()\n",
    "ai = pd.DataFrame(df.groupby(['type', 'year', 'country'])['paper_id'].count().loc['ai'].sort_values(ascending=False)).reset_index()\n",
    "ci = pd.DataFrame(df.groupby(['type', 'year', 'country'])['paper_id'].count().loc['ci'].sort_values(ascending=False)).reset_index()\n",
    "\n",
    "ci['type'] = 'ci'\n",
    "ai['type'] = 'ai'\n",
    "ai_ci['type'] = 'ai_ci'\n",
    "\n",
    "df = pd.concat([ci, ai_ci])\n",
    "df = df[df.country.isin(['United States', 'China', 'United Kingdom'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_bar(opacity=1).encode(\n",
    "    x=alt.X('country:N', title=None),\n",
    "    y=alt.Y('paper_id:Q', title='Number of total publications'),\n",
    "    color=alt.Color('type:N'),\n",
    "    column='year'\n",
    ").properties(\n",
    "    width=35\n",
    ").configure_facet(\n",
    "    spacing=18\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_ci = pd.DataFrame(df.groupby(['type', 'year', 'country'])['paper_id'].count().loc['ai_ci'].sort_values(ascending=False) / df.groupby(['type', 'year'])['paper_id'].count().loc['ai_ci'] * 100).reset_index()\n",
    "ai = pd.DataFrame(df.groupby(['type', 'year', 'country'])['paper_id'].count().loc['ai'].sort_values(ascending=False) / df.groupby(['type', 'year'])['paper_id'].count().loc['ai'] * 100).reset_index()\n",
    "ci = pd.DataFrame(df.groupby(['type', 'year', 'country'])['paper_id'].count().loc['ci'].sort_values(ascending=False) / df.groupby(['type', 'year'])['paper_id'].count().loc['ci'] * 100).reset_index()\n",
    "\n",
    "ci['type'] = 'ci'\n",
    "ai['type'] = 'ai'\n",
    "ai_ci['type'] = 'ai_ci'\n",
    "\n",
    "df = pd.concat([ci, ai_ci])\n",
    "df = df[df.country.isin(['United States', 'China', 'United Kingdom'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_bar(opacity=1).encode(\n",
    "    x=alt.X('country:N', title=None),\n",
    "    y=alt.Y('paper_id:Q', title='(%) of total publications'),\n",
    "    color=alt.Color('type:N'),\n",
    "    column='year'\n",
    ").properties(\n",
    "    width=35\n",
    ").configure_facet(\n",
    "    spacing=18\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [WIP] Country-level citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff_location = aff_location.dropna(subset=['country'])\n",
    "# merge paper_apaper_author_aff with location data\n",
    "df = paper_author_aff.merge(aff_location[['affiliation_id', 'country']], left_on='affiliation_id', right_on='affiliation_id').merge(mag[['id', 'citations']], left_on='paper_id', right_on='id')\n",
    "df = df.drop_duplicates(['paper_id', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_us = df[(df.type=='ci') & (df.country=='United States')][['year', 'citations', 'country']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [WIP] Research spillovers - % of researchers that publish mainly in X that have also published in Y or Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = paper_author_aff.groupby('author_id')['type'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_contrib_author_ids = frame.where(frame>1).dropna().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_contrib_author_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_author_aff[paper_author_aff.author_id==3022127360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
